{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Adrian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Adrian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Adrian/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "text                 object\n",
      "user_description     object\n",
      "user_name            object\n",
      "user_screen_name     object\n",
      "HasDiabetes         float64\n",
      "Type_Diabetes         int64\n",
      "Sexe                 object\n",
      "History_HasDiab      object\n",
      "History_TypeDiab    float64\n",
      "History_Sex          object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>HasDiabetes</th>\n",
       "      <th>Type_Diabetes</th>\n",
       "      <th>Sexe</th>\n",
       "      <th>History_HasDiab</th>\n",
       "      <th>History_TypeDiab</th>\n",
       "      <th>History_Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Dmartelz24 @Dterrazas760 Then diabetes Kankle...</td>\n",
       "      <td>Account Manager for Dr.Pepper Snapple Group. D...</td>\n",
       "      <td>Jimmy Martinez</td>\n",
       "      <td>R8TERFAN1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Woke up with a 30 blood sugar, hate half a can...</td>\n",
       "      <td>It's worth it.</td>\n",
       "      <td>Kelsey Smith</td>\n",
       "      <td>Kelsey_Smith88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I‚Äôm going back to my roots. I‚Äôm trying shakes ...</td>\n",
       "      <td>Life isn't about surviving the storms...it's a...</td>\n",
       "      <td>Lennie Ledesma</td>\n",
       "      <td>lennieledesma</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Praying I don‚Äôt get diabetes</td>\n",
       "      <td>I'm still not fat I'm just short for my weight...</td>\n",
       "      <td>Regina George üíé</td>\n",
       "      <td>BlowindatPINK_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy world diabetes todayüíôüíô #t1dstrong https:...</td>\n",
       "      <td>I have a dead pancreas‚òπÔ∏è santiagoüê¨</td>\n",
       "      <td>riley:)</td>\n",
       "      <td>itsRiMay</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @Dmartelz24 @Dterrazas760 Then diabetes Kankle...   \n",
       "1  Woke up with a 30 blood sugar, hate half a can...   \n",
       "2  I‚Äôm going back to my roots. I‚Äôm trying shakes ...   \n",
       "3                       Praying I don‚Äôt get diabetes   \n",
       "4  Happy world diabetes todayüíôüíô #t1dstrong https:...   \n",
       "\n",
       "                                    user_description        user_name  \\\n",
       "0  Account Manager for Dr.Pepper Snapple Group. D...   Jimmy Martinez   \n",
       "1                                     It's worth it.     Kelsey Smith   \n",
       "2  Life isn't about surviving the storms...it's a...   Lennie Ledesma   \n",
       "3  I'm still not fat I'm just short for my weight...  Regina George üíé   \n",
       "4                 I have a dead pancreas‚òπÔ∏è santiagoüê¨          riley:)   \n",
       "\n",
       "  user_screen_name  HasDiabetes  Type_Diabetes Sexe History_HasDiab  \\\n",
       "0        R8TERFAN1          0.0              0    M             NaN   \n",
       "1   Kelsey_Smith88          1.0              1    U             NaN   \n",
       "2    lennieledesma          1.0              0    U             NaN   \n",
       "3   BlowindatPINK_          0.0              0    F             NaN   \n",
       "4         itsRiMay          1.0              1    F             NaN   \n",
       "\n",
       "   History_TypeDiab History_Sex  \n",
       "0               NaN         NaN  \n",
       "1               NaN           M  \n",
       "2               NaN           M  \n",
       "3               NaN         NaN  \n",
       "4               NaN         NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import unicodedata\n",
    "import sys\n",
    "from gensim.models import FastText\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "\n",
    "basename = \"/Users/Adrian/Desktop/WDDS/Tweet-Classification-Diabetes-Distress/\"\n",
    "path_utils = op.join(basename , \"utils\")\n",
    "sys.path.insert(0, path_utils)\n",
    "\n",
    "from sys_utils import load_library\n",
    "from tweet_utils import *\n",
    "\n",
    "from preprocess import Preprocess\n",
    "prep = Preprocess()\n",
    "\n",
    "model_we = FastText.load(\"/Users/Adrian/Desktop/WDDS/Models_Data/FastText_model/ft_wordembeddings_09112018.model\")\n",
    "\n",
    "trainingData = pd.read_csv(\"ManualLabel_TypeDiabetes_Sexe.csv\", usecols=[\"text\", \"user_description\", \"user_name\", \"user_screen_name\", \"HasDiabetes\", \n",
    "                            \"Type_Diabetes\", \"Sexe\", \"History_HasDiab\", \"History_TypeDiab\", \"History_Sex\"],\n",
    "                           #converters={'user_description': lambda x: tt(x)}\n",
    "                           #converters={'HasDiabetes': lambda x: int(x, 16)}\n",
    "                          #dtype={'Type_Diabetes':np.int32}\n",
    "                          )\n",
    "\n",
    "\n",
    "print(trainingData.dtypes)\n",
    "trainingData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = prep.replace_hashtags_URL_USER(tweet, mode_URL=\"replace\", mode_Mentions=\"replace\")\n",
    "    tweet = prep.tokenize(tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def create_history_typeDiabetes_column(row):\n",
    "    #print(row)\n",
    "    if row[\"History_TypeDiab\"] == 0: return 0\n",
    "    elif row[\"History_TypeDiab\"] == 1: return 1\n",
    "    elif row[\"History_TypeDiab\"] == 2: return 2\n",
    "    elif pd.isnull(row[\"History_TypeDiab\"]): return row[\"Type_Diabetes\"]\n",
    "    else: print(\"ERROR: Should not occur:  \", row[\"Type_Diabetes\"], \";;;\", row[\"Type_Diabetes\"])\n",
    "\n",
    "trainingData['history_typeDiab_total'] = trainingData.apply (lambda row: create_history_typeDiabetes_column(row), axis=1)\n",
    "\n",
    "#typeDiab = trainingData.Type_Diabetes\n",
    "#history_typeDiab = trainingData.History_TypeDiab\n",
    "#trainingData[[\"Type_Diabetes\", \"History_TypeDiab\", \"history_typeDiab_total\"]].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Adrian/miniconda3/envs/deepscience/lib/python3.6/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for ùô∏ !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for ‚ìÉ !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Adrian/miniconda3/envs/deepscience/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1897, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_name</th>\n",
       "      <th>history_typeDiab_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.052558694, -0.24522443, -0.04574593, 0.007...</td>\n",
       "      <td>[0.0594463, -0.24121243, 0.023320783, 0.037211...</td>\n",
       "      <td>[-0.2699949, -0.47404158, -1.2414215, 0.562889...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.17099294, -0.24480842, -0.025194122, 0.0785...</td>\n",
       "      <td>[0.036096215, -0.17107086, -0.037160706, 0.252...</td>\n",
       "      <td>[0.16247262, -0.3107078, 0.49041492, 0.2769825...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.007961513, -0.26821032, 0.025039103, 0.081...</td>\n",
       "      <td>[0.17841837, -0.23252276, 0.06851852, 0.101422...</td>\n",
       "      <td>[0.4043988, -0.17029561, -0.51770705, 0.031111...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.044520285, -0.17575471, -0.02043754, 0.195...</td>\n",
       "      <td>[0.020974915, -0.26072818, -0.03475415, -0.014...</td>\n",
       "      <td>[-0.17914288, 0.12587129, -0.033790197, 0.2921...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.07020979, -0.3512135, -0.13412549, 0.082883...</td>\n",
       "      <td>[-0.0017228028, -0.2881601, -0.19797775, 0.156...</td>\n",
       "      <td>[0.23955466, -0.21134971, -0.02606355, -0.0738...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.10825033, -0.3565059, -0.102283314, 0.12660...</td>\n",
       "      <td>[-0.023374202, -0.17000306, -0.051754106, 0.27...</td>\n",
       "      <td>[0.19590783, -0.6297532, -0.25813368, 0.044850...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.09420633, -0.23973195, 0.04927173, 0.175991...</td>\n",
       "      <td>[0.009820584, -0.2773481, -0.12507488, 0.13536...</td>\n",
       "      <td>[-0.1073126, -0.17132345, 0.049530875, -0.1189...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.08068111, -0.34675863, -0.13565584, 0.17624...</td>\n",
       "      <td>[0.03981484, -0.30023643, -0.10133021, 0.09285...</td>\n",
       "      <td>[0.15172936, 0.02190333, -0.07081486, -0.05972...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.23827031, -0.2484061, 0.006873705, 0.228655...</td>\n",
       "      <td>[0.007466847, -0.19677974, -0.13833447, -0.035...</td>\n",
       "      <td>[0.16368158, 0.17193627, 0.037896816, -0.06315...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.20168515, -0.22820863, -0.14189078, 0.17853...</td>\n",
       "      <td>[-0.12554029, -0.1510367, 0.024744986, 0.15665...</td>\n",
       "      <td>[-0.09591146, -0.24816388, -0.22909127, -0.698...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [-0.052558694, -0.24522443, -0.04574593, 0.007...   \n",
       "1  [0.17099294, -0.24480842, -0.025194122, 0.0785...   \n",
       "2  [-0.007961513, -0.26821032, 0.025039103, 0.081...   \n",
       "3  [-0.044520285, -0.17575471, -0.02043754, 0.195...   \n",
       "4  [0.07020979, -0.3512135, -0.13412549, 0.082883...   \n",
       "5  [0.10825033, -0.3565059, -0.102283314, 0.12660...   \n",
       "6  [0.09420633, -0.23973195, 0.04927173, 0.175991...   \n",
       "7  [0.08068111, -0.34675863, -0.13565584, 0.17624...   \n",
       "8  [0.23827031, -0.2484061, 0.006873705, 0.228655...   \n",
       "9  [0.20168515, -0.22820863, -0.14189078, 0.17853...   \n",
       "\n",
       "                                    user_description  \\\n",
       "0  [0.0594463, -0.24121243, 0.023320783, 0.037211...   \n",
       "1  [0.036096215, -0.17107086, -0.037160706, 0.252...   \n",
       "2  [0.17841837, -0.23252276, 0.06851852, 0.101422...   \n",
       "3  [0.020974915, -0.26072818, -0.03475415, -0.014...   \n",
       "4  [-0.0017228028, -0.2881601, -0.19797775, 0.156...   \n",
       "5  [-0.023374202, -0.17000306, -0.051754106, 0.27...   \n",
       "6  [0.009820584, -0.2773481, -0.12507488, 0.13536...   \n",
       "7  [0.03981484, -0.30023643, -0.10133021, 0.09285...   \n",
       "8  [0.007466847, -0.19677974, -0.13833447, -0.035...   \n",
       "9  [-0.12554029, -0.1510367, 0.024744986, 0.15665...   \n",
       "\n",
       "                                           user_name  history_typeDiab_total  \n",
       "0  [-0.2699949, -0.47404158, -1.2414215, 0.562889...                       0  \n",
       "1  [0.16247262, -0.3107078, 0.49041492, 0.2769825...                       1  \n",
       "2  [0.4043988, -0.17029561, -0.51770705, 0.031111...                       0  \n",
       "3  [-0.17914288, 0.12587129, -0.033790197, 0.2921...                       0  \n",
       "4  [0.23955466, -0.21134971, -0.02606355, -0.0738...                       1  \n",
       "5  [0.19590783, -0.6297532, -0.25813368, 0.044850...                       0  \n",
       "6  [-0.1073126, -0.17132345, 0.049530875, -0.1189...                       0  \n",
       "7  [0.15172936, 0.02190333, -0.07081486, -0.05972...                       0  \n",
       "8  [0.16368158, 0.17193627, 0.037896816, -0.06315...                       0  \n",
       "9  [-0.09591146, -0.24816388, -0.22909127, -0.698...                       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label = \"Type_Diabetes\"\n",
    "label = \"history_typeDiab_total\"\n",
    "data_pd = trainingData[[\"text\", \"user_description\", \"user_name\", label]]\n",
    "data_pd.head()\n",
    "\n",
    "data_pd.text = data_pd.text.map(lambda tweet: tweet_vectorizer(preprocess_tweet(tweet), model_we))\n",
    "data_pd.user_description = data_pd.user_description.map(lambda userDesc: np.zeros((200, )) \n",
    "                                                if isinstance(userDesc, float) or userDesc == \" \" \n",
    "                                                else tweet_vectorizer(preprocess_tweet(userDesc), model_we))\n",
    "\n",
    "def userName_to_vec(name):\n",
    "    #print(\"name:\", name)\n",
    "    try:\n",
    "        firstName = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode('utf-8', 'ignore').split(\" \")[0].replace(\" \", \"\")\n",
    "        vec = model_we[firstName]\n",
    "    except:\n",
    "        vec = np.zeros((200, ))\n",
    "\n",
    "    return vec\n",
    "\n",
    "def TEMP_userName_to_vec(name):\n",
    "    #print(\"name:\", name)\n",
    "    try:\n",
    "        firstName = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode('utf-8', 'ignore').split(\" \")[0].replace(\" \", \"\")\n",
    "        vec = model_we[firstName]\n",
    "        return 1\n",
    "    except:\n",
    "        #vec = np.zeros((200, ))\n",
    "        return 0\n",
    "\n",
    "\n",
    "data_pd.user_name = data_pd.user_name.map(lambda name: userName_to_vec(name))\n",
    "#data_pd[label] = data_pd[label].map(labelEncode)\n",
    "\n",
    "\n",
    "# remove the tweets that are empty because there is no word embedding\n",
    "data_pd = data_pd[data_pd[\"text\"].apply(lambda x: len(x)>0) ]\n",
    "print(data_pd.shape)\n",
    "\n",
    "#data_pd.user_name = data_pd.user_name.map(lambda tweet: prep.remove_non_ascii(tweet))\n",
    "data_pd.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemSelect(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return np.asarray(data[self.key].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose algo:\n",
    "#---------------------------------------------------------------------------\n",
    "modelAlgo = \"SVC\"\n",
    "\n",
    "if modelAlgo == \"MultinomialNB\":\n",
    "    model = MultinomialNB(random_state=0)\n",
    "elif modelAlgo == \"SVC\":\n",
    "    model = SVC(random_state=0)\n",
    "elif modelAlgo == \"logReg\":\n",
    "    model = LogisticRegression(random_state=0)\n",
    "elif modelAlgo == \"RandomForest\" :\n",
    "    model = RandomForestClassifier(random_state=0)\n",
    "elif modelAlgo == \"XGBoost\" :\n",
    "    model = XGBClassifier(random_state=0)\n",
    "elif modelAlgo == \"MLP\" :\n",
    "    model = MLPClassifier(early_stopping=True, batch_size=32, random_state=0)\n",
    "\n",
    "from imblearn.pipeline import Pipeline    \n",
    "    \n",
    "pipeline  = Pipeline([\n",
    "                #(\"debuge\", Debug(\"start\")),\n",
    "                ('union', FeatureUnion(\n",
    "                            transformer_list = [\n",
    "                                ('tweet', Pipeline([\n",
    "                                    ('tweetsSelector', ItemSelect(key='text')),\n",
    "                                    #(\"debugeq\", Debug(\"text Selector\")),\n",
    "                                ])),  \n",
    "                                ('userDesc', Pipeline([\n",
    "                                    ('userDescSelector', ItemSelect(key='user_description'))\n",
    "                                ])),\n",
    "#                                ('userName', Pipeline([\n",
    "#                                    ('userNameSelector', ItemSelect(key='user_name'))\n",
    "#                                ]))     \n",
    "                            ],\n",
    "                )),\n",
    "                #(\"debuggg\", Debug(\"before model\")),\n",
    "                ('smote', SMOTE(random_state=12, sampling_strategy=\"auto\", n_jobs=-1)), # , ratio = 1.0\n",
    "                ('model', model),\n",
    "                #(\"debuggg\", Debug(\"after model\")),\n",
    "            ])\n",
    "\n",
    "\n",
    "# parameter grid for grid search by using fastText embeddings\n",
    "parameters = {\n",
    "                'union__transformer_weights' : #[#{\"tweet\": 1, \"userDesc\":1, \"userName\":1},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":1, \"userName\":0.8}, \n",
    "#                                                {\"tweet\": 1, \"userDesc\":1, \"userName\":0.5},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":1, \"userName\":0.5},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":1, \"userName\":0.4},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.8, \"userName\":0.4},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.8, \"userName\":0.5},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.8, \"userName\":0.6},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.7, \"userName\":0.5},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.9, \"userName\":0.5},\n",
    "#                                                ],\n",
    "                                               [#{\"tweet\": 1, \"userDesc\":1}, \n",
    "                                                {\"tweet\": 1, \"userDesc\":0.7}, \n",
    "                                                {\"tweet\": 1, \"userDesc\":0.5},\n",
    "                                                {\"tweet\": 1, \"userDesc\":0.3},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.1},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.0},\n",
    "#                                                {\"tweet\": 0, \"userDesc\":1}\n",
    "                                                ],\n",
    "    \n",
    "               'smote__k_neighbors' : [2, 3, 4, 5],\n",
    "\n",
    "#               # param for SVC\n",
    "               'model__kernel' : [\"linear\"],#[\"linear\", \"poly\", \"rbf\"],\n",
    "               'model__C' : [0.5, 0.1, 0.01],\n",
    "               'model__tol' : [1e-1, 1e-2, 1e-3],\n",
    "#               'model__class_weight' : [\"balanced\", {0:1, 1:1, 2:1}, {0:1, 1:2, 2:1}, {0:1, 1:1, 2:2}, {0:1, 1:2, 2:2}],\n",
    "#\n",
    "#               # param for RandomForestClassifier\n",
    "#               'model__n_estimators' : [50, 100, 150],\n",
    "#               'model__criterion' : ['gini', 'entropy'],\n",
    "#               'model__max_features' : ['auto', 'log2'],\n",
    "#               'model__max_depth' : [ 5, 10, 20, 30]\n",
    "#\n",
    "#               # param for XGBoost Best: 0.910828 using {'model__learning_rate': 0.05, 'model__reg_alpha': 0, 'model__max_depth': 3, 'model__reg_lambda': 1.5, 'model__n_estimators': 300}\n",
    "#               'model__max_depth' : [3,4],\n",
    "#               'model__learning_rate' : [0.5, 0.1, 0.05],#, 0.01, 0.001],\n",
    "#               'model__booster' : [\"gblinear\"], #[\"gbtree\", \"gblinear\", \"dart\"],\n",
    "#               'model__gamma' : [0, 0.01],\n",
    "#               'model__n_estimators' : [80, 100, 150],\n",
    "#               'model__reg_alpha' : [0, 0.1],\n",
    "#               'model__reg_lambda' : [0.5, 1.0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data before filter out gestational diabetes: (1897, 4) <class 'pandas.core.frame.DataFrame'>\n",
      "X : (1889, 2) <class 'pandas.core.frame.DataFrame'>\n",
      "y.unique:  [0 1 2]\n",
      "0    825\n",
      "2    539\n",
      "1    525\n",
      "Name: history_typeDiab_total, dtype: int64\n",
      "Start Grid search...\n",
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 353 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=6)]: Done 636 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=6)]: Done 1001 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=6)]: Done 1080 out of 1080 | elapsed: 14.3min finished\n",
      "/Users/Adrian/miniconda3/envs/deepscience/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best: 0.739032 using {'model__C': 0.5, 'model__kernel': 'linear', 'model__tol': 0.01, 'smote__k_neighbors': 3, 'union__transformer_weights': {'tweet': 1, 'userDesc': 0.3}}\n",
      "Accuracy:  0.7372134038800705\n",
      "Performance overall: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76       243\n",
      "           1       0.72      0.69      0.71       157\n",
      "           2       0.75      0.72      0.73       167\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       567\n",
      "   macro avg       0.74      0.73      0.73       567\n",
      "weighted avg       0.74      0.74      0.74       567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def label_encode(sex):\n",
    "    # no type 0, type 1 = 1, type 2 = 2\n",
    "    if sex == 0: return(-1) \n",
    "    else: return(1)\n",
    "    \n",
    "    \n",
    "print(\"data before filter out gestational diabetes:\", data_pd.shape, type(data_pd))\n",
    "data_pd_withoutGestational = data_pd.loc[data_pd[label] != 3]\n",
    "\n",
    "#data_pd_withoutGestational = data_pd_withoutGestational.loc[data_pd[label] != 0]\n",
    "\n",
    "#print(\"data after before filter out gestational diabetes:\", data_pd_withoutGestational.shape, type(data_pd_withoutGestational))\n",
    "X = data_pd_withoutGestational[[\"text\", \"user_description\"]]\n",
    "y = data_pd_withoutGestational[label]\n",
    "#X = data_pd[[\"text\", \"user_description\"]]\n",
    "#y = data_pd[label]#.map(label_encode)\n",
    "#y = data_pd_withoutGestational[label]#.map(label_encode)\n",
    "\n",
    "\n",
    "#temp = data_pd.loc[data_pd[label] != 2]\n",
    "#print(\"Temp:\", temp.shape, type(temp))\n",
    "#X = temp[[\"text\", \"user_description\"]]\n",
    "#y = temp[label].map(label_encode)\n",
    "print(\"X :\", X.shape, type(X))\n",
    "print(\"y.unique: \", y.unique())\n",
    "print(y.value_counts())\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) \n",
    "\n",
    "    # Over sample traininig set\n",
    "    #sm = SMOTE(random_state=12, ratio = 1.0, n_jobs=-1)\n",
    "    #X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "#    ros = RandomOverSampler(random_state=0)\n",
    "#    X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
    "#    print(\"X_train_res:\", X_train_res.shape, type(X_train_res))\n",
    "\n",
    "#    X_train_pd = pd.DataFrame(X_train_res, columns=[\"text\", \"user_description\", \"user_name\"])\n",
    "#    X_test_pd = pd.DataFrame(X_test, columns=[\"text\", \"user_description\", \"user_name\"])\n",
    "X_train_pd = pd.DataFrame(X_train, columns=[\"text\", \"user_description\"])\n",
    "X_test_pd = pd.DataFrame(X_test, columns=[\"text\", \"user_description\"])\n",
    "\n",
    "#from sklearn.metrics import precision_score, roc_auc_score, make_scorer\n",
    "prec_scorer = make_scorer(precision_score, average=\"micro\")\n",
    "print(\"Start Grid search...\")\n",
    "grid = GridSearchCV(pipeline, parameters, cv=10, n_jobs=6, verbose=2, scoring=prec_scorer)\n",
    "grid.fit(X_train_pd, y_train)\n",
    "print(\"\\nBest: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "\n",
    "    #grid.best_estimator_#.fit(X_train_res, y_train_res)\n",
    "y_pred = grid.best_estimator_.predict(X_test_pd)\n",
    "#print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "#print(\"Precision: \",precision_score(y_test, y_pred))\n",
    "#print(\"Recall: \", recall_score(y_test, y_pred))    \n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))   \n",
    "print(\"Performance overall: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take this one\n",
    "\n",
    "# SVC - no SMOTE\n",
    "#Best: 0.733737 using {'model__C': 0.5, 'model__kernel': 'linear', 'model__tol': 0.1, 'union__transformer_weights': {'tweet': 1, 'userDesc': 0.5}}\n",
    "#Accuracy:  0.7530864197530864\n",
    "#Performance overall: \n",
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#           0       0.71      0.87      0.78       243\n",
    "#           1       0.83      0.69      0.75       157\n",
    "#           2       0.78      0.64      0.70       167\n",
    "\n",
    "#   micro avg       0.75      0.75      0.75       567\n",
    "#   macro avg       0.77      0.73      0.75       567\n",
    "#weighted avg       0.76      0.75      0.75       567\n",
    "\n",
    "\n",
    "# SVC - SMOTE\n",
    "#Best: 0.739032 using {'model__C': 0.5, 'model__kernel': 'linear', 'model__tol': 0.01, 'smote__k_neighbors': 3, 'union__transformer_weights': {'tweet': 1, 'userDesc': 0.3}}\n",
    "#Accuracy:  0.7372134038800705\n",
    "#Performance overall: \n",
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#           0       0.74      0.78      0.76       243\n",
    "#           1       0.72      0.69      0.71       157\n",
    "#           2       0.75      0.72      0.73       167\n",
    "\n",
    "#   micro avg       0.74      0.74      0.74       567\n",
    "#   macro avg       0.74      0.73      0.73       567\n",
    "#weighted avg       0.74      0.74      0.74       567\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['typeDiabetes_classifier.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(grid.best_estimator_, 'typeDiabetes_classifier.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f64706d6fa2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                           \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                           \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                           cmap=plt.cm.Blues):\n\u001b[0m\u001b[1;32m      6\u001b[0m     \"\"\"\n\u001b[1;32m      7\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mprints\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mplots\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconfusion\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    print(\"Classes before:\", classes)\n",
    "    print(\"unique labels:\", unique_labels(y_true, y_pred))\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    print(\"Classes:\", classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "#class_names = np.array([\"M\", \"F\", \"U\"])\n",
    "class_names = np.array([\"Unknown\", \"Type 1\", \"Type 2\"])\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict having diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>HasDiabetes</th>\n",
       "      <th>Type_Diabetes</th>\n",
       "      <th>Sexe</th>\n",
       "      <th>History_HasDiab</th>\n",
       "      <th>History_TypeDiab</th>\n",
       "      <th>History_Sex</th>\n",
       "      <th>HaveDiab_merge</th>\n",
       "      <th>history_typeDiab_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Dmartelz24 @Dterrazas760 Then diabetes Kankle...</td>\n",
       "      <td>Account Manager for Dr.Pepper Snapple Group. D...</td>\n",
       "      <td>Jimmy Martinez</td>\n",
       "      <td>R8TERFAN1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Woke up with a 30 blood sugar, hate half a can...</td>\n",
       "      <td>It's worth it.</td>\n",
       "      <td>Kelsey Smith</td>\n",
       "      <td>Kelsey_Smith88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I‚Äôm going back to my roots. I‚Äôm trying shakes ...</td>\n",
       "      <td>Life isn't about surviving the storms...it's a...</td>\n",
       "      <td>Lennie Ledesma</td>\n",
       "      <td>lennieledesma</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Praying I don‚Äôt get diabetes</td>\n",
       "      <td>I'm still not fat I'm just short for my weight...</td>\n",
       "      <td>Regina George üíé</td>\n",
       "      <td>BlowindatPINK_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy world diabetes todayüíôüíô #t1dstrong https:...</td>\n",
       "      <td>I have a dead pancreas‚òπÔ∏è santiagoüê¨</td>\n",
       "      <td>riley:)</td>\n",
       "      <td>itsRiMay</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @Dmartelz24 @Dterrazas760 Then diabetes Kankle...   \n",
       "1  Woke up with a 30 blood sugar, hate half a can...   \n",
       "2  I‚Äôm going back to my roots. I‚Äôm trying shakes ...   \n",
       "3                       Praying I don‚Äôt get diabetes   \n",
       "4  Happy world diabetes todayüíôüíô #t1dstrong https:...   \n",
       "\n",
       "                                    user_description        user_name  \\\n",
       "0  Account Manager for Dr.Pepper Snapple Group. D...   Jimmy Martinez   \n",
       "1                                     It's worth it.     Kelsey Smith   \n",
       "2  Life isn't about surviving the storms...it's a...   Lennie Ledesma   \n",
       "3  I'm still not fat I'm just short for my weight...  Regina George üíé   \n",
       "4                 I have a dead pancreas‚òπÔ∏è santiagoüê¨          riley:)   \n",
       "\n",
       "  user_screen_name  HasDiabetes  Type_Diabetes Sexe History_HasDiab  \\\n",
       "0        R8TERFAN1          0.0              0    M             NaN   \n",
       "1   Kelsey_Smith88          1.0              1    U             NaN   \n",
       "2    lennieledesma          1.0              0    U             NaN   \n",
       "3   BlowindatPINK_          0.0              0    F             NaN   \n",
       "4         itsRiMay          1.0              1    F             NaN   \n",
       "\n",
       "   History_TypeDiab History_Sex  HaveDiab_merge  history_typeDiab_total  \n",
       "0               NaN         NaN             0.0                       0  \n",
       "1               NaN           M             1.0                       1  \n",
       "2               NaN           M             1.0                       0  \n",
       "3               NaN         NaN             0.0                       0  \n",
       "4               NaN         NaN             1.0                       1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1364\n",
       "1.0     532\n",
       "Name: HaveDiab_merge, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = prep.replace_hashtags_URL_USER(tweet, mode_URL=\"replace\", mode_Mentions=\"replace\")\n",
    "    tweet = prep.tokenize(tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def create_haveDiab_column(row):\n",
    "    if isinstance(row[\"History_HasDiab\"], str): return row[\"HasDiabetes\"]\n",
    "    elif float(row[\"History_HasDiab\"]) < 1e-9: return 0\n",
    "    elif float(row[\"History_HasDiab\"])-1 < 1e-9: return 1\n",
    "    elif pd.isnull(row[\"History_HasDiab\"]) : return row[\"HasDiabetes\"]\n",
    "    else: print(\"ERROR: Should not occur:  \", row[\"HasDiabetes\"], \";;;\", row[\"History_HasDiab\"])\n",
    "\n",
    "trainingData['HaveDiab_merge'] = trainingData.apply (lambda row: create_haveDiab_column(row), axis=1)\n",
    "\n",
    "trainingData.HaveDiab_merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Adrian/miniconda3/envs/deepscience/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for ùô∏ !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for ‚ìÉ !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "no embedding for \" !!!!!!!!!!!!\n",
      "Index(['text', 'user_description', 'user_name', 'history_typeDiab_total'], dtype='object')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Adrian/miniconda3/envs/deepscience/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  import sys\n",
      "/Users/Adrian/miniconda3/envs/deepscience/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'text_vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/deepscience/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text_vec'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-8ffbf68ed03c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# remove the tweets that are empty because there is no word embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdata_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_pd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_pd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text_vec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepscience/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepscience/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepscience/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepscience/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepscience/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text_vec'"
     ]
    }
   ],
   "source": [
    "#label = \"Type_Diabetes\"\n",
    "label = \"history_typeDiab_total\"\n",
    "data_pd = trainingData[[\"text\", \"user_description\", \"user_name\", label]]\n",
    "data_pd.head()\n",
    "\n",
    "data_pd[\"text_vec\"] = data_pd.text.map(lambda tweet: tweet_vectorizer(preprocess_tweet(tweet), model_we))\n",
    "data_pd[\"user_description_vec = data_pd.user_description.map(lambda userDesc: np.zeros((model_we.vector_size, )) \n",
    "                                                if isinstance(userDesc, float) or userDesc == \" \" \n",
    "                                                else tweet_vectorizer(preprocess_tweet(userDesc), model_we))\n",
    "\n",
    "def userName_to_vec(name):\n",
    "    #print(\"name:\", name)\n",
    "    try:\n",
    "        firstName = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode('utf-8', 'ignore').split(\" \")[0].replace(\" \", \"\")\n",
    "        vec = model_we[firstName]\n",
    "    except:\n",
    "        vec = np.zeros((model_we.vector_size, ))\n",
    "\n",
    "    return vec\n",
    "\n",
    "data_pd.user_name = data_pd.user_name.map(lambda name: userName_to_vec(name))\n",
    "\n",
    "print(data_pd.columns)\n",
    "\n",
    "# remove the tweets that are empty because there is no word embedding\n",
    "data_pd = data_pd[data_pd[\"text_vec\"].apply(lambda x: len(x)>0) ]\n",
    "print(data_pd.shape)\n",
    "\n",
    "#data_pd.user_name = data_pd.user_name.map(lambda tweet: prep.remove_non_ascii(tweet))\n",
    "data_pd.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose algo:\n",
    "#---------------------------------------------------------------------------\n",
    "modelAlgo = \"SVC\"\n",
    "\n",
    "if modelAlgo == \"MultinomialNB\":\n",
    "    model = MultinomialNB(random_state=0)\n",
    "elif modelAlgo == \"SVC\":\n",
    "    model = SVC(random_state=0)\n",
    "elif modelAlgo == \"logReg\":\n",
    "    model = LogisticRegression(random_state=0)\n",
    "elif modelAlgo == \"RandomForest\" :\n",
    "    model = RandomForestClassifier(random_state=0)\n",
    "elif modelAlgo == \"XGBoost\" :\n",
    "    model = XGBClassifier(random_state=0)\n",
    "elif modelAlgo == \"MLP\" :\n",
    "    model = MLPClassifier(early_stopping=True, batch_size=32, random_state=0)\n",
    "\n",
    "from imblearn.pipeline import Pipeline    \n",
    "    \n",
    "pipeline  = Pipeline([\n",
    "                #(\"debuge\", Debug(\"start\")),\n",
    "                ('union', FeatureUnion(\n",
    "                            transformer_list = [\n",
    "                                ('tweet', Pipeline([\n",
    "                                    ('tweetsSelector', ItemSelect(key='text')),\n",
    "                                    #(\"debugeq\", Debug(\"text Selector\")),\n",
    "                                ])),  \n",
    "                                ('userDesc', Pipeline([\n",
    "                                    ('userDescSelector', ItemSelect(key='user_description'))\n",
    "                                ])),\n",
    "#                                ('userName', Pipeline([\n",
    "#                                    ('userNameSelector', ItemSelect(key='user_name'))\n",
    "#                                ]))     \n",
    "                            ],\n",
    "                )),\n",
    "                #(\"debuggg\", Debug(\"before model\")),\n",
    "                ('smote', SMOTE(random_state=12, sampling_strategy=\"auto\", n_jobs=-1)), # , ratio = 1.0\n",
    "                ('model', model),\n",
    "                #(\"debuggg\", Debug(\"after model\")),\n",
    "            ])\n",
    "\n",
    "\n",
    "# parameter grid for grid search by using fastText embeddings\n",
    "parameters = {\n",
    "                'union__transformer_weights' : #[#{\"tweet\": 1, \"userDesc\":1, \"userName\":1},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":1, \"userName\":0.8}, \n",
    "#                                                {\"tweet\": 1, \"userDesc\":1, \"userName\":0.5},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":1, \"userName\":0.5},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":1, \"userName\":0.4},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.8, \"userName\":0.4},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.8, \"userName\":0.5},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.8, \"userName\":0.6},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.7, \"userName\":0.5},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.9, \"userName\":0.5},\n",
    "#                                                ],\n",
    "                                               [#{\"tweet\": 1, \"userDesc\":1}, \n",
    "                                                {\"tweet\": 1, \"userDesc\":0.7}, \n",
    "                                                {\"tweet\": 1, \"userDesc\":0.5},\n",
    "                                                {\"tweet\": 1, \"userDesc\":0.3},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.1},\n",
    "#                                                {\"tweet\": 1, \"userDesc\":0.0},\n",
    "#                                                {\"tweet\": 0, \"userDesc\":1}\n",
    "                                                ],\n",
    "    \n",
    "               'smote__k_neighbors' : [2, 3, 4, 5],\n",
    "\n",
    "#               # param for SVC\n",
    "               'model__kernel' : [\"linear\"],#[\"linear\", \"poly\", \"rbf\"],\n",
    "               'model__C' : [0.5, 0.1, 0.01],\n",
    "               'model__tol' : [1e-1, 1e-2, 1e-3],\n",
    "#               'model__class_weight' : [\"balanced\", {0:1, 1:1, 2:1}, {0:1, 1:2, 2:1}, {0:1, 1:1, 2:2}, {0:1, 1:2, 2:2}],\n",
    "#\n",
    "#               # param for RandomForestClassifier\n",
    "#               'model__n_estimators' : [50, 100, 150],\n",
    "#               'model__criterion' : ['gini', 'entropy'],\n",
    "#               'model__max_features' : ['auto', 'log2'],\n",
    "#               'model__max_depth' : [ 5, 10, 20, 30]\n",
    "#\n",
    "#               # param for XGBoost Best: 0.910828 using {'model__learning_rate': 0.05, 'model__reg_alpha': 0, 'model__max_depth': 3, 'model__reg_lambda': 1.5, 'model__n_estimators': 300}\n",
    "#               'model__max_depth' : [3,4],\n",
    "#               'model__learning_rate' : [0.5, 0.1, 0.05],#, 0.01, 0.001],\n",
    "#               'model__booster' : [\"gblinear\"], #[\"gbtree\", \"gblinear\", \"dart\"],\n",
    "#               'model__gamma' : [0, 0.01],\n",
    "#               'model__n_estimators' : [80, 100, 150],\n",
    "#               'model__reg_alpha' : [0, 0.1],\n",
    "#               'model__reg_lambda' : [0.5, 1.0]\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
