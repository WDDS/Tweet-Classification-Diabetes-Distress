{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/adrian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/adrian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/adrian/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "\n",
    "basename = \"/home/adrian/PhD/Tweet-Classification-Diabetes-Distress/\"\n",
    "path_utils = op.join(basename , \"utils\")\n",
    "sys.path.insert(0, path_utils)\n",
    "\n",
    "from sys_utils import load_library\n",
    "from tweet_utils import tweet_vectorizer\n",
    "from defines import Patterns, Emotions\n",
    "from emotion_codes import UNICODE_EMOJI, EMOJI_TO_CATEGORY\n",
    "from preprocess import Preprocess\n",
    "prep = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'created_at', 'lang', 'text', 'user_name', 'user_screen_name',\n",
      "       'user_followers_count', 'user_friends_count', 'user_location',\n",
      "       'user_description', 'place_full_name', 'retweeted_user_name',\n",
      "       'retweeted_user_screen_name', 'retweeted_user_followers_count',\n",
      "       'retweeted_user_friends_count', 'retweeted_user_location',\n",
      "       'retweeted_user_description', 'retweeted_place_full_name',\n",
      "       'retweeted_text', 'posted_month', 'tweet_URL_USER', '__index_level_0__',\n",
      "       '__index_level_1__', 'geo_id', 'geo_name', 'geo_code', 'geo_type',\n",
      "       'geo_country_code', 'geo_city_code', 'geo_adm1_code', 'geo_adm2_code',\n",
      "       'geo_adm3_code', 'geo_adm4_code', 'pop', '_score_', '_tags_',\n",
      "       '_startIndex_', '_endIndex_'],\n",
      "      dtype='object')\n",
      "(167743, 38)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>...</th>\n",
       "      <th>geo_city_code</th>\n",
       "      <th>geo_adm1_code</th>\n",
       "      <th>geo_adm2_code</th>\n",
       "      <th>geo_adm3_code</th>\n",
       "      <th>geo_adm4_code</th>\n",
       "      <th>pop</th>\n",
       "      <th>_score_</th>\n",
       "      <th>_tags_</th>\n",
       "      <th>_startIndex_</th>\n",
       "      <th>_endIndex_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.675721e+17</td>\n",
       "      <td>Thu May 25 02:44:51 +0000 2017</td>\n",
       "      <td>en</td>\n",
       "      <td>@kristilade It doesn't suck. I have it. It wor...</td>\n",
       "      <td>Wil Gentry</td>\n",
       "      <td>wilable70</td>\n",
       "      <td>926.0</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Be yourself. No on else wants to be you.</td>\n",
       "      <td>...</td>\n",
       "      <td>5809844</td>\n",
       "      <td>WA</td>\n",
       "      <td>033</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.545088</td>\n",
       "      <td>221.237152</td>\n",
       "      <td>Seattle,WA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.129140e+18</td>\n",
       "      <td>Thu May 16 21:42:52 +0000 2019</td>\n",
       "      <td>en</td>\n",
       "      <td>When I was initially diagnosed with #type2diab...</td>\n",
       "      <td>Lynda Jimenez</td>\n",
       "      <td>lyndajimenez22</td>\n",
       "      <td>30.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Boymom living with LADA #diabetes.  Employee a...</td>\n",
       "      <td>...</td>\n",
       "      <td>5308655</td>\n",
       "      <td>AZ</td>\n",
       "      <td>013</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.626851</td>\n",
       "      <td>262.320343</td>\n",
       "      <td>Phoenix,AZ</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.102559e+18</td>\n",
       "      <td>Mon Mar 04 13:17:40 +0000 2019</td>\n",
       "      <td>en</td>\n",
       "      <td>Later Twitter it's back to sleep for a nap wok...</td>\n",
       "      <td>Deanna Porter Weick</td>\n",
       "      <td>deanna_weick</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>Monroe, MI</td>\n",
       "      <td>Native American Potowatomi adopted out  raised...</td>\n",
       "      <td>...</td>\n",
       "      <td>5002344</td>\n",
       "      <td>MI</td>\n",
       "      <td>115</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.231201</td>\n",
       "      <td>225.749695</td>\n",
       "      <td>Monroe,MI</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.087817e+18</td>\n",
       "      <td>Tue Jan 22 20:58:04 +0000 2019</td>\n",
       "      <td>en</td>\n",
       "      <td>Please read this! There are people dying becau...</td>\n",
       "      <td>BTSARMYMOM</td>\n",
       "      <td>cure4t1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>Rogers</td>\n",
       "      <td>Mom, Music lover, BTS ARMY member (thanks to m...</td>\n",
       "      <td>...</td>\n",
       "      <td>4533580</td>\n",
       "      <td>OK</td>\n",
       "      <td>131</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.227495</td>\n",
       "      <td>133.306839</td>\n",
       "      <td>Rogers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.641931e+17</td>\n",
       "      <td>Mon May 15 18:57:38 +0000 2017</td>\n",
       "      <td>en</td>\n",
       "      <td>My stepson was 4 or 5. Damn you kids with your...</td>\n",
       "      <td>Writing as I Go</td>\n",
       "      <td>WritingAsIGo</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>Colorado Springs, Colorado</td>\n",
       "      <td>Starting the job hunt again. Book Reviewer whi...</td>\n",
       "      <td>...</td>\n",
       "      <td>5417598</td>\n",
       "      <td>CO</td>\n",
       "      <td>041</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.505316</td>\n",
       "      <td>322.702881</td>\n",
       "      <td>Colorado,Springs,Colorado</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                      created_at lang  \\\n",
       "0  8.675721e+17  Thu May 25 02:44:51 +0000 2017   en   \n",
       "1  1.129140e+18  Thu May 16 21:42:52 +0000 2019   en   \n",
       "2  1.102559e+18  Mon Mar 04 13:17:40 +0000 2019   en   \n",
       "3  1.087817e+18  Tue Jan 22 20:58:04 +0000 2019   en   \n",
       "4  8.641931e+17  Mon May 15 18:57:38 +0000 2017   en   \n",
       "\n",
       "                                                text            user_name  \\\n",
       "0  @kristilade It doesn't suck. I have it. It wor...           Wil Gentry   \n",
       "1  When I was initially diagnosed with #type2diab...        Lynda Jimenez   \n",
       "2  Later Twitter it's back to sleep for a nap wok...  Deanna Porter Weick   \n",
       "3  Please read this! There are people dying becau...           BTSARMYMOM   \n",
       "4  My stepson was 4 or 5. Damn you kids with your...      Writing as I Go   \n",
       "\n",
       "  user_screen_name  user_followers_count  user_friends_count  \\\n",
       "0        wilable70                 926.0              2920.0   \n",
       "1   lyndajimenez22                  30.0                70.0   \n",
       "2     deanna_weick                2222.0              2721.0   \n",
       "3          cure4t1                 122.0               840.0   \n",
       "4     WritingAsIGo                 485.0              1195.0   \n",
       "\n",
       "                user_location  \\\n",
       "0                 Seattle, WA   \n",
       "1                 Phoenix, AZ   \n",
       "2                  Monroe, MI   \n",
       "3                      Rogers   \n",
       "4  Colorado Springs, Colorado   \n",
       "\n",
       "                                    user_description  ... geo_city_code  \\\n",
       "0           Be yourself. No on else wants to be you.  ...       5809844   \n",
       "1  Boymom living with LADA #diabetes.  Employee a...  ...       5308655   \n",
       "2  Native American Potowatomi adopted out  raised...  ...       5002344   \n",
       "3  Mom, Music lover, BTS ARMY member (thanks to m...  ...       4533580   \n",
       "4  Starting the job hunt again. Book Reviewer whi...  ...       5417598   \n",
       "\n",
       "   geo_adm1_code  geo_adm2_code  geo_adm3_code  geo_adm4_code       pop  \\\n",
       "0             WA            033           None           None  1.545088   \n",
       "1             AZ            013           None           None  1.626851   \n",
       "2             MI            115           None           None  1.231201   \n",
       "3             OK            131           None           None  1.227495   \n",
       "4             CO            041           None           None  1.505316   \n",
       "\n",
       "      _score_                     _tags_  _startIndex_  _endIndex_  \n",
       "0  221.237152                 Seattle,WA             0           2  \n",
       "1  262.320343                 Phoenix,AZ             0           2  \n",
       "2  225.749695                  Monroe,MI             0           2  \n",
       "3  133.306839                     Rogers             0           1  \n",
       "4  322.702881  Colorado,Springs,Colorado             0           3  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_parquet(\"/home/adrian/PhD/Data/Tweets20190708/matching-tweets_diab_noRT-noBots_personal_noJokes_locationUS_geoCityCodeNotNull.parquet\", engine=\"pyarrow\")\n",
    "print(tweets.columns)\n",
    "print(tweets.shape)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38316, 39)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check_emoticonEmoji_in_tweet(tweet):\n",
    "    \"\"\" Check if in each tweet occurs either an emoji or emoticon \"\"\"\n",
    "    tweet = prep.replace_hashtags_URL_USER(tweet, mode_URL=\"delete\", mode_Mentions=\"delete\")\n",
    "    tweet = prep.tokenize(tweet)\n",
    "\n",
    "    for word in tweet: \n",
    "        match_emoticon = Patterns.EMOTICONS_PATTERN.findall(word)\n",
    "        \n",
    "        # if emoticon found\n",
    "        if match_emoticon:\n",
    "            if match_emoticon[0] is not \":\" and match_emoticon[0] is not \")\": return True\n",
    "            \n",
    "        # if emoji found    \n",
    "        if word in UNICODE_EMOJI: \n",
    "            emot_cat = EMOJI_TO_CATEGORY[UNICODE_EMOJI[word]]\n",
    "            if emot_cat != \"\": return True\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_emotKeywords(tweet):\n",
    "    tweet = prep.replace_hashtags_URL_USER(tweet, mode_URL=\"delete\", mode_Mentions=\"delete\")\n",
    "    tweet = tweet.replace(\"nerve pain\", \"\")\n",
    "    tweet = tweet.replace(\"nerve damage\", \"\")\n",
    "    tweet = tweet.replace(\"pain of neuropathy\", \"\")\n",
    "    tweet = prep.tokenize(tweet)\n",
    "    tweet = prep.remove_punctuation(tweet)\n",
    "    tweet = prep.to_lowercase(tweet)\n",
    "    tweet = [word for word in tweet if word not in [\"healthcare\"]]\n",
    "\n",
    "    for word in tweet:\n",
    "        for emot in Emotions.emotions_full_list:\n",
    "            if emot == word: return True\n",
    "    return False\n",
    "\n",
    "\n",
    "tweets[\"emotion\"] = tweets.text.map(lambda tweet: check_emoticonEmoji_in_tweet(tweet) or check_emotKeywords(tweet))\n",
    "\n",
    "emot_tweets = tweets[tweets[\"emotion\"] == True]\n",
    "print(emot_tweets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@kristilade It doesn't suck. I have it. It works for me. I wouldn't have found out I have diabetes without it. Now… https://t.co/kHS8R9STVC\n",
      "False\n",
      "\n",
      "When I was initially diagnosed with #type2diabetes almost 10 years ago, I was in a dark place - blaming myself, fee… https://t.co/pLtFgM2wKr\n",
      "False\n",
      "\n",
      "Later Twitter it's back to sleep for a nap woke up at 5:30am to let the puppies out. Took my diabetic meds had an e… https://t.co/7TxMvXmEja\n",
      "True\n",
      "\n",
      "Please read this! There are people dying because they can’t afford their insulin!\n",
      "False\n",
      "\n",
      "My stepson was 4 or 5. Damn you kids with your #type1diabetes and your rock and roll. https://t.co/sASXzNOG6Z\n",
      "False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "for i, row in tweets[[\"text\", \"emotion\"]].head().iterrows():\n",
    "    print(row[\"text\"])\n",
    "    print(row[\"emotion\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('😂', 1343), ('❤', 1263), ('😭', 1202), ('💙', 926), ('🙄', 804), (':)', 655), ('😩', 643), ('🙃', 639), ('😍', 411), (':(', 335), ('😢', 314), ('😊', 284), ('😔', 273), ('😒', 269), ('😡', 262), ('dx', 229), ('😳', 226), ('🤢', 225), ('💕', 225), ('🤣', 221), ('😁', 205), ('😞', 201), ('💜', 178), ('🤗', 166), (':3', 159), (':/', 156), ('♥', 152), ('😀', 138), ('😕', 135), ('😱', 129), ('🙂', 127), ('😓', 121), ('😷', 119), ('😥', 114), (';)', 102), ('☺', 96), ('💖', 96), ('😤', 94), ('💗', 87), ('😃', 86), (':-)', 86), ('💋', 73), (':D', 72), ('😄', 68), ('😘', 68), ('):', 67), ('🙁', 64), ('😆', 61), ('😰', 55), ('💚', 55), ('💛', 53), ('😇', 52), ('😲', 49), ('😠', 48), ('Dx', 48), ('😮', 41), ('😻', 40), ('💓', 39), ('😨', 37), ('💞', 36), ('💩', 31), ('DX', 27), ('😵', 26), ('😯', 26), (':P', 24), ('(:', 22), ('0:3', 21), ('💫', 20), ('XD', 19), ('😧', 17), ('😿', 17), ('xD', 14), (':p', 11), ('🙀', 10), (\":')\", 10), (\":'(\", 10), ('dX', 9), ('=/', 9), (';D', 9), ('D:', 8), ('😺', 8), ('😸', 8), ('xd', 7), ('😹', 7), ('t.T', 7), ('=d', 6), ('😚', 6), ('💟', 6), ('=D', 5), ('QQ', 5), (':]', 5), (';d', 5), (':|', 4), ('😽', 4), ('t.t', 4), ('👿', 3), ('😗', 3), ('=)', 3), ('😙', 3), ('💏', 2), ('😾', 2), ('D;', 2), (':[', 2), ('=p', 2), (':d', 2), ('8D', 2), ('>:(', 2), ('💢', 1), (':*', 1), ('=P', 1), ('d:', 1), (':o', 1), ('D=', 1), ('=\\\\', 1), ('D8', 1), ('=(', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Get most often occuring emoticons or emojis\n",
    "import operator\n",
    "\n",
    "emotico_dict = {}\n",
    "\n",
    "for tweet in tweets.text:\n",
    "    tweet = prep.replace_hashtags_URL_USER(tweet, mode_URL=\"delete\", mode_Mentions=\"delete\")\n",
    "    tweet = prep.tokenize(tweet)\n",
    "    for word in tweet: \n",
    "        match_emoticon = Patterns.EMOTICONS_PATTERN.findall(word)\n",
    "        \n",
    "        # if emoticon found\n",
    "        if match_emoticon:\n",
    "            if match_emoticon[0] is not \":\" and match_emoticon[0] is not \")\":\n",
    "                if match_emoticon[0] in emotico_dict: emotico_dict[match_emoticon[0]] += 1\n",
    "                else : emotico_dict[match_emoticon[0]] = 1\n",
    "                \n",
    "        # if emoji found    \n",
    "        if word in UNICODE_EMOJI: \n",
    "            emot_cat = EMOJI_TO_CATEGORY[UNICODE_EMOJI[word]]\n",
    "            if emot_cat != \"\": \n",
    "                if word in emotico_dict: emotico_dict[word] += 1\n",
    "                else : emotico_dict[word] = 1\n",
    "                \n",
    "sorted_x = sorted(emotico_dict.items(), key=operator.itemgetter(1))[::-1]\n",
    "print(sorted_x)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good', 4834), ('love', 3044), ('feel', 2340), ('bad', 2139), ('care', 1913), ('hope', 1861), ('happy', 1806), ('sick', 1126), ('hate', 1066), ('understand', 974), ('glad', 833), ('amazing', 771), ('pain', 739), ('sad', 725), ('excited', 720), ('awesome', 698), ('depression', 538), ('poor', 491), ('shock', 487), ('worry', 485), ('alone', 431), ('funny', 387), ('worried', 362), ('anxiety', 342), ('terrible', 333), ('fear', 316), ('horrible', 307), ('attention', 294), ('loved', 294), ('stress', 289), ('suffer', 275), ('enjoy', 274), ('awful', 251), ('hurt', 250), ('shame', 239), ('surprised', 229), ('crying', 227), ('beat', 221), ('suffering', 216), ('broken', 204), ('despite', 201), ('cry', 198), ('mad', 190), ('angry', 185), ('nervous', 184), ('sadly', 161), ('outrageous', 160), ('trust', 159), ('cried', 158), ('trouble', 154), ('fail', 149), ('upset', 147), ('loving', 146), ('refuse', 143), ('affect', 135), ('catch', 134), ('sensitive', 131), ('disgusting', 129), ('annoying', 124), ('impact', 122), ('pissed', 119), ('terrifying', 117), ('depressed', 114), ('frustrating', 114), ('concern', 111), ('damage', 111), ('scare', 110), ('exciting', 109), ('shocked', 107), ('surprise', 106), ('terrified', 103), ('joy', 99), ('promise', 98), ('caring', 97), ('painful', 95), ('panic', 90), ('ashamed', 86), ('emotional', 82), ('stressed', 80), ('appreciated', 80), ('hurting', 78), ('frustrated', 77), ('worrying', 75), ('nerve', 73), ('dreading', 72), ('relief', 71), ('disappointed', 70), ('fairly', 69), ('screw', 67), ('headache', 63), ('tend', 62), ('desperately', 62), ('bear', 61), ('subject', 61), ('injury', 58), ('amazed', 57), ('desperate', 56), ('dark', 53), ('rage', 52), ('miserable', 51), ('lecture', 51), ('anxious', 51), ('starve', 51), ('hated', 49), ('block', 48), ('infuriating', 48), ('passion', 47), ('guilty', 47), ('bother', 46), ('abuse', 46), ('pleasure', 45), ('content', 45), ('thrilled', 45), ('annoyed', 45), ('horror', 45), ('solid', 43), ('rush', 42), ('disgusted', 41), ('fascinating', 41), ('horrific', 41), ('guilt', 40), ('happiness', 40), ('dislike', 39), ('awkward', 37), ('moderate', 37), ('pathetic', 36), ('shocking', 36), ('dread', 36), ('harm', 35), ('compassion', 35), ('curse', 35), ('merry', 35), ('lean', 34), ('jealous', 34), ('outrage', 34), ('shameful', 34), ('inflammation', 33), ('shake', 33), ('depressing', 33), ('moderation', 33), ('torture', 33), ('nerves', 33), ('excitement', 32), ('anger', 32), ('surprising', 31), ('defeated', 31), ('frustration', 31), ('rally', 31), ('disgrace', 31), ('desire', 31), ('liking', 30), ('disappointing', 30), ('unconscionable', 30), ('sweetness', 30), ('trauma', 29), ('eliminate', 29), ('furious', 29), ('awe', 28), ('horrifying', 28), ('crush', 28), ('defeat', 27), ('beloved', 27), ('spite', 27), ('maintenance', 26), ('victory', 26), ('threat', 26), ('regret', 26), ('sympathy', 26), ('embarrassing', 25), ('embarrassed', 25), ('gladly', 24), ('appalled', 23), ('cheering', 23), ('disturbing', 23), ('grief', 23), ('outraged', 23), ('ignored', 22), ('frightening', 22), ('exorbitant', 21), ('madness', 21), ('outrageously', 21), ('rejected', 21), ('cranky', 20), ('dreaded', 20), ('cheer', 20), ('appalling', 20), ('grumpy', 19), ('bruise', 19), ('celebration', 19), ('happily', 19), ('pity', 18), ('lonely', 18), ('violence', 18), ('substance', 18), ('sunshine', 17), ('satisfied', 17), ('sadness', 17), ('irritated', 17), ('pleasant', 16), ('pinch', 16), ('tolerate', 15), ('distress', 15), ('optimistic', 15), ('kindly', 15), ('satisfying', 15), ('terrific', 15), ('raging', 15), ('isolated', 15), ('horrendous', 14), ('ecstatic', 14), ('fierce', 14), ('empathize', 14), ('humbled', 14), ('crushed', 14), ('sympathetic', 14), ('shamed', 14), ('spooky', 14), ('crave', 14), ('boot', 13), ('square', 13), ('understandable', 13), ('despise', 13), ('attractive', 13), ('bitter', 13), ('curb', 13), ('dependency', 13), ('lover', 13), ('misery', 13), ('unhappy', 12), ('hopeless', 12), ('stunned', 12), ('cult', 12), ('eager', 12), ('excruciating', 11), ('humbling', 11), ('cushion', 11), ('panicked', 11), ('disgraceful', 11), ('frightened', 11), ('queer', 11), ('dreadful', 11), ('beautifully', 11), ('pesky', 11), ('offend', 10), ('horrid', 10), ('yucky', 10), ('endure', 10), ('separated', 10), ('hatred', 10), ('digest', 10), ('comforting', 10), ('insecure', 10), ('grasp', 10), ('neglect', 10), ('staggering', 10), ('stranded', 9), ('isolation', 9), ('maddening', 9), ('grim', 9), ('irritating', 9), ('bid', 9), ('disregard', 9), ('worrisome', 9), ('moody', 9), ('sufferer', 9), ('sham', 9), ('brace', 9), ('spoil', 8), ('harassed', 8), ('fearful', 8), ('scandal', 8), ('inconvenience', 8), ('tease', 8), ('troubling', 8), ('stimulate', 8), ('loathe', 8), ('horrified', 8), ('aggravated', 7), ('delighted', 7), ('astounded', 7), ('amaze', 7), ('agonizing', 7), ('disappointment', 7), ('disposition', 7), ('resent', 7), ('rejoice', 7), ('leaning', 7), ('sympathize', 7), ('sustain', 7), ('lone', 7), ('flush', 7), ('discomfort', 7), ('triumph', 7), ('appealing', 7), ('settled', 7), ('astounding', 7), ('restless', 7), ('reject', 7), ('tension', 7), ('spice', 7), ('extortionate', 7), ('randy', 7), ('queasy', 7), ('lust', 7), ('attendant', 6), ('rape', 6), ('disrespect', 6), ('amused', 6), ('worship', 6), ('neglected', 6), ('grieve', 6), ('envy', 6), ('charitable', 6), ('puzzle', 6), ('enraged', 6), ('disgust', 6), ('unsafe', 6), ('temper', 6), ('entertainment', 6), ('embarrassment', 6), ('despair', 6), ('rebuke', 6), ('disappoint', 6), ('depress', 6), ('delight', 6), ('ruth', 5), ('terrorist', 5), ('embarrass', 5), ('frantic', 5), ('distressing', 5), ('negligence', 5), ('revolt', 5), ('depressant', 5), ('shocker', 5), ('atrocious', 5), ('hostile', 5), ('grieving', 5), ('joyful', 5), ('sticky', 5), ('laughable', 5), ('elicit', 5), ('savor', 5), ('continent', 5), ('attraction', 5), ('moderately', 5), ('tortured', 5), ('annoy', 5), ('rejection', 5), ('stimulating', 5), ('agony', 5), ('anxiously', 5), ('compassionate', 5), ('mourning', 5), ('congratulate', 5), ('provoke', 5), ('eagerly', 5), ('strained', 5), ('berate', 5), ('tense', 5), ('fermentation', 5), ('crabby', 5), ('turmoil', 4), ('aggravating', 4), ('loneliness', 4), ('wishful', 4), ('coveted', 4), ('enthusiasm', 4), ('scold', 4), ('aggression', 4), ('compound', 4), ('bliss', 4), ('angrily', 4), ('brutality', 4), ('fond', 4), ('thrill', 4), ('teasing', 4), ('heartbreak', 4), ('tendency', 4), ('propensity', 4), ('stimulant', 4), ('revolting', 4), ('jaundice', 4), ('scourge', 4), ('thrilling', 4), ('astonishing', 4), ('desperation', 4), ('ramp', 4), ('reliever', 4), ('pitiful', 4), ('jolly', 4), ('stamp', 4), ('assault', 4), ('tormented', 4), ('craze', 4), ('delirious', 4), ('disturbed', 4), ('licking', 4), ('hater', 4), ('frighten', 4), ('enjoyment', 4), ('insecurity', 4), ('torturing', 3), ('negligent', 3), ('elated', 3), ('disdain', 3), ('envious', 3), ('infuriated', 3), ('bait', 3), ('galling', 3), ('rack', 3), ('scandalous', 3), ('gloom', 3), ('warmth', 3), ('spicy', 3), ('isolate', 3), ('humiliating', 3), ('affection', 3), ('fussy', 3), ('desired', 3), ('loathing', 3), ('diverted', 3), ('hysteria', 3), ('diss', 3), ('frenzy', 3), ('annoyance', 3), ('harrowing', 3), ('grouchy', 3), ('optimism', 3), ('despised', 3), ('amusing', 3), ('stimulation', 3), ('contempt', 3), ('uneasy', 3), ('delirium', 3), ('detest', 3), ('excite', 3), ('amazement', 3), ('stimulated', 3), ('brat', 3), ('stupor', 3), ('energise', 3), ('stung', 3), ('isolating', 3), ('frustrate', 3), ('dismayed', 3), ('affirmative', 3), ('regrets', 3), ('detached', 3), ('gratification', 2), ('scotch', 2), ('savvy', 2), ('wounded', 2), ('teaser', 2), ('humiliation', 2), ('hopelessly', 2), ('nervously', 2), ('fright', 2), ('terrify', 2), ('jealousy', 2), ('tenacious', 2), ('incorporate', 2), ('tender', 2), ('cutter', 2), ('tending', 2), ('vindictive', 2), ('combative', 2), ('gravel', 2), ('virulent', 2), ('unattended', 2), ('abomination', 2), ('empathise', 2), ('hideous', 2), ('dun', 2), ('wretched', 2), ('astonish', 2), ('distasteful', 2), ('conjure', 2), ('exacerbating', 2), ('fervor', 2), ('satisfaction', 2), ('upbeat', 2), ('carelessness', 2), ('gloating', 2), ('furiously', 2), ('woefully', 2), ('jittery', 2), ('fondly', 2), ('obscure', 2), ('heartache', 2), ('yearn', 2), ('potty', 2), ('protagonist', 2), ('respite', 2), ('wrath', 2), ('bore', 2), ('detriment', 2), ('feign', 2), ('plethora', 2), ('dismal', 2), ('satisfy', 2), ('lovable', 2), ('torturous', 2), ('savagery', 2), ('tingle', 2), ('gloomy', 2), ('simulate', 2), ('apprehensive', 2), ('spew', 2), ('weakened', 2), ('thriller', 2), ('relish', 2), ('easing', 2), ('bonk', 2), ('chagrin', 2), ('enthusiastic', 2), ('entertained', 2), ('agonist', 2), ('hopelessness', 2), ('craved', 2), ('vengeful', 1), ('savory', 1), ('quarantined', 1), ('infuriate', 1), ('uptight', 1), ('displeasure', 1), ('mortifying', 1), ('thorn', 1), ('adoration', 1), ('distressed', 1), ('joyfully', 1), ('venom', 1), ('irritant', 1), ('aghast', 1), ('sprinkle', 1), ('aflutter', 1), ('humiliated', 1), ('foiled', 1), ('stir', 1), ('ecstasy', 1), ('cull', 1), ('commiseration', 1), ('irritate', 1), ('exasperated', 1), ('yearning', 1), ('usurious', 1), ('blithely', 1), ('uplift', 1), ('wildness', 1), ('irritation', 1), ('acrid', 1), ('cheerful', 1), ('elating', 1), ('charmed', 1), ('dismay', 1), ('boldness', 1), ('nark', 1), ('gloat', 1), ('crow', 1), ('fain', 1), ('spunk', 1), ('hullabaloo', 1), ('victorious', 1), ('jealously', 1), ('caustic', 1), ('crabbed', 1), ('injure', 1), ('vibrate', 1), ('fulfil', 1), ('glum', 1), ('enormity', 1), ('resentment', 1), ('jubilant', 1), ('peeved', 1), ('agonize', 1), ('elation', 1), ('gusto', 1), ('rapture', 1), ('baffle', 1), ('pestered', 1), ('rejoicing', 1), ('prevail', 1), ('malaise', 1), ('benevolent', 1), ('riled', 1), ('amuse', 1), ('sorrow', 1), ('blockade', 1), ('mortified', 1), ('bereft', 1), ('reprimand', 1), ('grumpiness', 1), ('glee', 1), ('hostility', 1), ('hapless', 1), ('shudder', 1), ('bitterness', 1), ('felicity', 1), ('lonesome', 1), ('readiness', 1), ('dishonor', 1), ('astound', 1), ('throb', 1), ('displeased', 1), ('attract', 1), ('commiserate', 1), ('aroused', 1), ('contemptuous', 1), ('savage', 1), ('sicken', 1), ('unrestrained', 1), ('colonizer', 1), ('nervousness', 1), ('restlessness', 1), ('disliked', 1), ('unrest', 1), ('apprehension', 1), ('foil', 1), ('drab', 1), ('steamed', 1), ('smitten', 1), ('jubilee', 1), ('merriment', 1), ('repent', 1), ('letdown', 1), ('thwarted', 1), ('adoring', 1), ('disposed', 1), ('sympathise', 1), ('quenched', 1), ('energize', 1), ('indignant', 1), ('terrorize', 1), ('revel', 1), ('edgy', 1), ('incensed', 1), ('astonished', 1), ('amusement', 1), ('bitterly', 1), ('wallow', 1), ('longing', 1), ('vexatious', 1), ('joyously', 1), ('precaution', 1), ('anguish', 1), ('violate', 1), ('invoke', 1), ('torment', 1), ('lovingly', 1), ('somber', 1), ('repellent', 1), ('agonising', 1), ('jumpy', 1), ('middling', 1), ('diverting', 1), ('lightness', 1), ('exhilarating', 1), ('dejected', 1), ('infliction', 1), ('sedative', 1), ('fondness', 1), ('joyous', 1), ('banter', 1), ('hearty', 1), ('discernment', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Get most often occuring emotional words\n",
    "emojo_dict = {}\n",
    "\n",
    "for tweet in tweets.text:\n",
    "    tweet = prep.replace_hashtags_URL_USER(tweet, mode_URL=\"delete\", mode_Mentions=\"delete\")\n",
    "    tweet = tweet.replace(\"nerve pain\", \"\")\n",
    "    tweet = tweet.replace(\"nerve damage\", \"\")\n",
    "    tweet = tweet.replace(\"pain of neuropathy\", \"\")\n",
    "    tweet = prep.tokenize(tweet)\n",
    "    tweet = prep.remove_punctuation(tweet)\n",
    "    tweet = prep.to_lowercase(tweet)\n",
    "    tweet = [word for word in tweet if word not in [\"healthcare\"]]\n",
    "    \n",
    "    for word in tweet:\n",
    "        for emot in Emotions.emotions_full_list:\n",
    "            \n",
    "            if emot == word: \n",
    "                if word in emojo_dict: emojo_dict[emot] += 1\n",
    "                else : emojo_dict[emot] = 1\n",
    "                    \n",
    "sorted_y = sorted(emojo_dict.items(), key=operator.itemgetter(1))[::-1]\n",
    "print(sorted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_tweets.to_parquet(\"/home/adrian/PhD/Data/Tweets20190708/matching-tweets_diab_noRT-noBots_personal_noJokes_locationUS_geoCityCodeNotNull_emotions.parquet\", \n",
    "                       engine=\"pyarrow\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>...</th>\n",
       "      <th>geo_adm1_code</th>\n",
       "      <th>geo_adm2_code</th>\n",
       "      <th>geo_adm3_code</th>\n",
       "      <th>geo_adm4_code</th>\n",
       "      <th>pop</th>\n",
       "      <th>_score_</th>\n",
       "      <th>_tags_</th>\n",
       "      <th>_startIndex_</th>\n",
       "      <th>_endIndex_</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.129140e+18</td>\n",
       "      <td>Thu May 16 21:42:52 +0000 2019</td>\n",
       "      <td>en</td>\n",
       "      <td>When I was initially diagnosed with #type2diab...</td>\n",
       "      <td>Lynda Jimenez</td>\n",
       "      <td>lyndajimenez22</td>\n",
       "      <td>30.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Boymom living with LADA #diabetes.  Employee a...</td>\n",
       "      <td>...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>013</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.626851</td>\n",
       "      <td>262.320343</td>\n",
       "      <td>Phoenix,AZ</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.102559e+18</td>\n",
       "      <td>Mon Mar 04 13:17:40 +0000 2019</td>\n",
       "      <td>en</td>\n",
       "      <td>Later Twitter it's back to sleep for a nap wok...</td>\n",
       "      <td>Deanna Porter Weick</td>\n",
       "      <td>deanna_weick</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>Monroe, MI</td>\n",
       "      <td>Native American Potowatomi adopted out  raised...</td>\n",
       "      <td>...</td>\n",
       "      <td>MI</td>\n",
       "      <td>115</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.231201</td>\n",
       "      <td>225.749695</td>\n",
       "      <td>Monroe,MI</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.039046e+18</td>\n",
       "      <td>Mon Sep 10 07:01:45 +0000 2018</td>\n",
       "      <td>en</td>\n",
       "      <td>Ugh not ready for this 3hour glucose test tomo...</td>\n",
       "      <td>Esmeralda</td>\n",
       "      <td>EsmeBayybee</td>\n",
       "      <td>751.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>Hemet CA</td>\n",
       "      <td>Mom too a Ghoul 💚🕸\\nZ.E.R.O👨‍👩‍👧‍👦</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>065</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.344957</td>\n",
       "      <td>201.460098</td>\n",
       "      <td>Hemet,CA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.581800e+17</td>\n",
       "      <td>Tue Jan 30 03:28:18 +0000 2018</td>\n",
       "      <td>en</td>\n",
       "      <td>@hotfunkytown They also lock up diabetic suppl...</td>\n",
       "      <td>Joyce Pride</td>\n",
       "      <td>joycepride</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>3466.0</td>\n",
       "      <td>Maryville, Missouri</td>\n",
       "      <td>Farm and Ranch Real Estate Locally &amp; Nationwid...</td>\n",
       "      <td>...</td>\n",
       "      <td>MO</td>\n",
       "      <td>147</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.199328</td>\n",
       "      <td>157.847015</td>\n",
       "      <td>Maryville,Missouri</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.151822e+17</td>\n",
       "      <td>Tue Oct 03 11:50:09 +0000 2017</td>\n",
       "      <td>en</td>\n",
       "      <td>@I_TheeWed “Hey mom! I know you’re dreading th...</td>\n",
       "      <td>Hot Mess Momma🍁</td>\n",
       "      <td>TattoosandLace</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>Illinois ✈️ Oklahoma</td>\n",
       "      <td>raised in the North now living in the South. w...</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>109</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.537132</td>\n",
       "      <td>206.331146</td>\n",
       "      <td>Illinois,Oklahoma</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                      created_at lang  \\\n",
       "1   1.129140e+18  Thu May 16 21:42:52 +0000 2019   en   \n",
       "2   1.102559e+18  Mon Mar 04 13:17:40 +0000 2019   en   \n",
       "11  1.039046e+18  Mon Sep 10 07:01:45 +0000 2018   en   \n",
       "12  9.581800e+17  Tue Jan 30 03:28:18 +0000 2018   en   \n",
       "15  9.151822e+17  Tue Oct 03 11:50:09 +0000 2017   en   \n",
       "\n",
       "                                                 text            user_name  \\\n",
       "1   When I was initially diagnosed with #type2diab...        Lynda Jimenez   \n",
       "2   Later Twitter it's back to sleep for a nap wok...  Deanna Porter Weick   \n",
       "11  Ugh not ready for this 3hour glucose test tomo...            Esmeralda   \n",
       "12  @hotfunkytown They also lock up diabetic suppl...          Joyce Pride   \n",
       "15  @I_TheeWed “Hey mom! I know you’re dreading th...      Hot Mess Momma🍁   \n",
       "\n",
       "   user_screen_name  user_followers_count  user_friends_count  \\\n",
       "1    lyndajimenez22                  30.0                70.0   \n",
       "2      deanna_weick                2222.0              2721.0   \n",
       "11      EsmeBayybee                 751.0               790.0   \n",
       "12       joycepride                1097.0              3466.0   \n",
       "15   TattoosandLace                1526.0               757.0   \n",
       "\n",
       "           user_location                                   user_description  \\\n",
       "1            Phoenix, AZ  Boymom living with LADA #diabetes.  Employee a...   \n",
       "2             Monroe, MI  Native American Potowatomi adopted out  raised...   \n",
       "11              Hemet CA                 Mom too a Ghoul 💚🕸\\nZ.E.R.O👨‍👩‍👧‍👦   \n",
       "12   Maryville, Missouri  Farm and Ranch Real Estate Locally & Nationwid...   \n",
       "15  Illinois ✈️ Oklahoma  raised in the North now living in the South. w...   \n",
       "\n",
       "    ... geo_adm1_code  geo_adm2_code  geo_adm3_code  geo_adm4_code       pop  \\\n",
       "1   ...            AZ            013           None           None  1.626851   \n",
       "2   ...            MI            115           None           None  1.231201   \n",
       "11  ...            CA            065           None           None  1.344957   \n",
       "12  ...            MO            147           None           None  1.199328   \n",
       "15  ...            OK            109           None           None  1.537132   \n",
       "\n",
       "       _score_              _tags_  _startIndex_  _endIndex_  emotion  \n",
       "1   262.320343          Phoenix,AZ             0           2     True  \n",
       "2   225.749695           Monroe,MI             0           2     True  \n",
       "11  201.460098            Hemet,CA             0           2     True  \n",
       "12  157.847015  Maryville,Missouri             0           2     True  \n",
       "15  206.331146   Illinois,Oklahoma             0           2     True  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emot_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
